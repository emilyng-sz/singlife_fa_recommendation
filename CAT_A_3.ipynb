{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional Usage of venv to download and install the required packages\n",
    "\n",
    "```bash\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports combined data to data/ folder by default. Change to False otherwise\n",
    "EXPORT_DATA = True\n",
    "# Exports model to model/ folder by default. Change to False otherwise\n",
    "EXPORT_MODELS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and functions\n",
    "Ensure Python version 3.12 is installed and in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "np.random.seed(59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and Data-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_df = pd.read_parquet('data/nus_agent_info_df.parquet', engine='pyarrow')\n",
    "client_df = pd.read_parquet('data/nus_client_info_df.parquet', engine='pyarrow')\n",
    "policy_df = pd.read_parquet('data/nus_policy_info_df.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the following columns:\n",
    "1. cluster: Criteria for old segment is unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_df = agent_df.drop(columns=[\"cluster\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expand `agent_product_expertise`. In other words, we create new variables, with each column indicating if the agent is comfortable selling the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_df_exploded = agent_df.explode(\"agent_product_expertise\")\n",
    "agent_df_encoded = pd.get_dummies(agent_df_exploded, columns=[\"agent_product_expertise\"])\n",
    "agent_df = agent_df_encoded.groupby(\"agntnum\").max().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some inspection, we realized there are some values that is labelled `U`, which means it is unknown/undisclosed. Hence we decided to remove those data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_df = agent_df.dropna()\n",
    "agent_df = agent_df[agent_df[\"agent_age\"] != \"U\"]\n",
    "agent_df = agent_df[agent_df[\"agent_gender\"] != \"U\"]\n",
    "agent_df = agent_df[agent_df[\"agent_marital\"] != \"U\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we one-hot-encode the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_variables(df, exclude_columns=None):\n",
    "    if exclude_columns is None:\n",
    "        exclude_columns = []\n",
    "    \n",
    "    # Select all categorical columns (exclude specified columns)\n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "    categorical_columns = [col for col in categorical_columns if col not in exclude_columns]\n",
    "    \n",
    "    # Apply one-hot encoding using get_dummies for all categorical columns\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)  # drop_first to avoid multicollinearity\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "agent_encoded_df = encode_categorical_variables(agent_df, exclude_columns=[\"agntnum\"])\n",
    "final_agent_df = agent_encoded_df.apply(lambda col: col.astype(int) if col.dtype == 'bool' else col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the same analysis, we drop the data points where there is unknown values. We also converted the dob to the person's age and decided not to use the postal code due to privacy concerns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = pd.read_parquet('data/nus_client_info_df.parquet', engine='pyarrow')\n",
    "client_df = client_df.dropna()\n",
    "client_df['cltdob'] = pd.to_datetime(client_df['cltdob'])\n",
    "today = pd.to_datetime('today')\n",
    "client_df['age'] = ((today - client_df['cltdob']).dt.days / 365.25).round()\n",
    "client_df = client_df[client_df[\"marryd\"] != \"U\"]\n",
    "client_df = client_df.drop(columns=[\"cltdob\", \"cltpcode\", \"household_size\", \"family_size\"])\n",
    "client_df = client_df[client_df[\"household_size_grp\"] != \"HH0_missing\"]\n",
    "client_encoded_df = encode_categorical_variables(client_df, exclude_columns=[\"secuityno\", \"economic_status\"])\n",
    "final_client_df = client_encoded_df.apply(lambda col: col.astype(int) if col.dtype == 'bool' else col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as the previous 2 datasets, we remove the unknown values, and convert the `occdate` variable to `time_elapsed`. We also dropped a few columns due to either lack of information in the data dictionary, or because their values are all the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_df = pd.read_parquet('data/nus_policy_info_df.parquet', engine='pyarrow')\n",
    "policy_df = policy_df.dropna()\n",
    "policy_df['occdate'] = pd.to_datetime(policy_df['occdate'])\n",
    "today = pd.to_datetime('today')\n",
    "policy_df['time_elapsed'] = ((today - policy_df['occdate']).dt.days / 365.25).round()\n",
    "policy_df = policy_df.drop(columns=[\"occdate\", \"flg_lapsed\", \"flg_main\", \"flg_rider\", \"flg_cancel\", \"flg_converted\", \"product_grp\"])\n",
    "policy_encoded_df = encode_categorical_variables(policy_df, exclude_columns=[\"secuityno\", \"agntnum\", \"chdrnum\"])\n",
    "final_policy_df = policy_encoded_df.apply(lambda col: col.astype(int) if col.dtype == 'bool' else col)\n",
    "final_policy_df ## Output is removed for data privacy reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we merge all the datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_policy_df = final_policy_df.merge(final_client_df, how=\"inner\", on=\"secuityno\")\n",
    "combined_df = client_policy_df.merge(final_agent_df, how=\"inner\", on=\"agntnum\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving of files\n",
    "if EXPORT_DATA == True:\n",
    "    combined_df.to_csv(\"data/combined_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read combined df\n",
    "if EXPORT_DATA == True:\n",
    "    df = pd.read_csv('data/combined_info.csv')\n",
    "else:\n",
    "    df = combined_df\n",
    "agent_df = pd.read_parquet('data/nus_agent_info_df.parquet', engine=\"pyarrow\")\n",
    "\n",
    "# set variables to be used in the model\n",
    "client_vars = ['cust_age_at_purchase_grp_AG01_lt20',\n",
    "        'cust_age_at_purchase_grp_AG07_45to49',\n",
    "       'cust_age_at_purchase_grp_AG08_50to54',\n",
    "       'cust_age_at_purchase_grp_AG09_55to59',\n",
    "       'cust_age_at_purchase_grp_AG10_60up','economic_status', 'age',\n",
    "       'cltsex_M', 'marryd_M', 'marryd_P', 'marryd_S', 'marryd_W',\n",
    "       'race_desc_map_Indian', 'race_desc_map_Malay', 'race_desc_map_Others',\n",
    "       'household_size_grp_HH2_40to80', 'household_size_grp_HH3_80to100',\n",
    "       'household_size_grp_HH4_100to120', 'household_size_grp_HH5_120up',\n",
    "       'family_size_grp_FS2_20to40', 'family_size_grp_FS3_40to60',\n",
    "       'family_size_grp_FS4_60to80', 'family_size_grp_FS5_80up']\n",
    "\n",
    "labels_to_predict = ['agent_age', 'agent_gender_M', 'agent_marital', 'agent_tenure', 'cnt_converted_cat', 'annual_premium_cnvrt_cat', 'agntnum'] # 'cnt_converted', 'annual_premium_cnvrt',\n",
    "\n",
    "## Functions to convert numerical to ordinal categories (in numbers) \n",
    "def cnt_converted_to_cat(num):\n",
    "    \"\"\"Convert cnt_converted into category bins of size 500.\"\"\"\n",
    "    return int(num // 500)\n",
    "\n",
    "def annual_premium_cnvrt_to_cat(num):\n",
    "    \"\"\"Convert annual_premium_cnvrt into category bins of size 4000000.\"\"\"\n",
    "    return int(num // 4000000) \n",
    "\n",
    "## Data Preprocessing \n",
    "## Preprocess client columns\n",
    "columns_to_scale = ['economic_status', 'age']\n",
    "scaler = StandardScaler()\n",
    "df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "## Preprocess label columns\n",
    "df = df.merge(agent_df[['agntnum','agent_marital']], on='agntnum', how='left')\n",
    "df['cnt_converted_cat'] = df['cnt_converted'].apply(cnt_converted_to_cat).astype(int)\n",
    "df['annual_premium_cnvrt_cat'] = df['annual_premium_cnvrt'].apply(annual_premium_cnvrt_to_cat).astype(int)\n",
    "## Split data into X and y_multiple\n",
    "X = df[client_vars]\n",
    "y_multiple = df[labels_to_predict]\n",
    "\n",
    "# Split dataset into testing and training (0.2 test data)\n",
    "X_train, X_test, y_train_multiple, y_test_multiple = train_test_split(X, y_multiple, test_size=0.2, random_state=59)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for agent_age\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilyng/Documents/Projects/singlife_fa_recommendation/myvenv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: agent_age\n",
      "Cross-validation accuracy scores: [0.36171797 0.36271102 0.3503849  0.34765334 0.35013658]\n",
      "Mean accuracy: 0.3545\n",
      "Standard deviation: 0.0064\n",
      "\n",
      "Training model for agent_gender_M\n",
      "Label: agent_gender_M\n",
      "Cross-validation accuracy scores: [0.66683217 0.6633565  0.67221257 0.66898436 0.6642662 ]\n",
      "Mean accuracy: 0.6671\n",
      "Standard deviation: 0.0032\n",
      "\n",
      "Training model for agent_tenure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilyng/Documents/Projects/singlife_fa_recommendation/myvenv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: agent_tenure\n",
      "Cross-validation accuracy scores: [0.32373386 0.3182721  0.31686119 0.30370002 0.32331761]\n",
      "Mean accuracy: 0.3172\n",
      "Standard deviation: 0.0073\n",
      "\n",
      "Training model for agent_marital\n",
      "Label: agent_marital\n",
      "Cross-validation accuracy scores: [0.67428004 0.65566038 0.67072262 0.67022597 0.67146759]\n",
      "Mean accuracy: 0.6685\n",
      "Standard deviation: 0.0066\n",
      "\n",
      "Training model for cnt_converted_cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilyng/Documents/Projects/singlife_fa_recommendation/myvenv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: cnt_converted_cat\n",
      "Cross-validation accuracy scores: [0.64920556 0.64995035 0.64117209 0.63695058 0.6548299 ]\n",
      "Mean accuracy: 0.6464\n",
      "Standard deviation: 0.0065\n",
      "\n",
      "Training model for annual_premium_cnvrt_cat\n",
      "Label: annual_premium_cnvrt_cat\n",
      "Cross-validation accuracy scores: [0.97467726 0.97269116 0.97566427 0.97491929 0.97616091]\n",
      "Mean accuracy: 0.9748\n",
      "Standard deviation: 0.0012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "        'agent_age': {\n",
    "                'model': RandomForestClassifier(max_features=None, n_jobs=-1) \n",
    "                },\n",
    "        'agent_gender_M' : {\n",
    "                'model': RandomForestClassifier(max_features=None, n_jobs=-1)\n",
    "                },\n",
    "        'agent_tenure' : {\n",
    "                'model': RandomForestClassifier(max_features=None, n_jobs=-1) \n",
    "                },\n",
    "        'agent_marital' : {\n",
    "                'model': RandomForestClassifier(max_features=None, n_jobs=-1)\n",
    "                },\n",
    "        'cnt_converted_cat' : {\n",
    "                'model': RandomForestClassifier(max_features=None, n_jobs=-1)\n",
    "                },\n",
    "        'annual_premium_cnvrt_cat' : {\n",
    "                'model': RandomForestClassifier(max_features=None, n_jobs=-1)\n",
    "                },\n",
    "        }\n",
    "\n",
    "# Initialise dataframe for concatenating y_pred for each label\n",
    "y_pred_multiple = pd.DataFrame()\n",
    "\n",
    "# Intialise fitted_model dictionary \n",
    "fitted_models = {}\n",
    "\n",
    "# Train, fit and predict for each label and corresponding model\n",
    "for label_name, dct in models.items():\n",
    "        print(f\"Training model for {label_name}\")\n",
    "\n",
    "        # Define y_train\n",
    "        y_train = y_train_multiple[label_name]\n",
    "        \n",
    "        # Cross validation score of model\n",
    "        model = dct['model']\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Compute mean and standard deviation\n",
    "        mean_score = np.mean(scores)\n",
    "        std_score = np.std(scores)\n",
    "        print(f\"Label: {label_name}\")\n",
    "        print(f\"Cross-validation accuracy scores: {scores}\")\n",
    "        print(f\"Mean accuracy: {mean_score:.4f}\")\n",
    "        print(f\"Standard deviation: {std_score:.4f}\")\n",
    "        print()\n",
    "\n",
    "        # Save model \n",
    "        fitted_models[label_name] = model        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_age accuracy score: 0.3926514399205561\n",
      "agent_gender_M accuracy score: 0.6796425024826217\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "# Predict\n",
    "for label_name in fitted_models:\n",
    "    model = fitted_models[label_name]\n",
    "    y_test = y_test_multiple[label_name]\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{label_name} accuracy score: {acc}\")\n",
    "\n",
    "    # append column to y_pred_multiple\n",
    "    y_pred_multiple[label_name] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Model Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode label `agent_marital`\n",
    "- `agent_marital` is currently a categorical datapoint. To calcualte the cosine similarity score, it needs to be one hot encoded for an accurate representation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_variables(df, exclude_columns=None):\n",
    "    if exclude_columns is None:\n",
    "        exclude_columns = []\n",
    "    \n",
    "    # Select all categorical columns (exclude specified columns)\n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "    categorical_columns = [col for col in categorical_columns if col not in exclude_columns]\n",
    "    \n",
    "    # Apply one-hot encoding using get_dummies for all categorical columns\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)  # drop_first to avoid multicollinearity\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "# This is All the agents data\n",
    "y_multiple = encode_categorical_variables(y_multiple, exclude_columns=[\"agntnum\"])\n",
    "y_multiple = y_multiple.apply(lambda col: col.astype(int) if col.dtype == 'bool' else col)\n",
    "y_multiple = y_multiple[[col for col in y_multiple.columns if col != 'agntnum'] + ['agntnum']]\n",
    "\n",
    "# This is the agent data test set\n",
    "y_test_multiple = encode_categorical_variables(y_test_multiple, exclude_columns=[\"agntnum\"])\n",
    "y_test_multiple = y_test_multiple.apply(lambda col: col.astype(int) if col.dtype == 'bool' else col)\n",
    "y_test_multiple = y_test_multiple[[col for col in y_test_multiple.columns if col != 'agntnum'] + ['agntnum']]\n",
    "\n",
    "# This is the predicted agent data, to be compared with the test set\n",
    "y_pred_multiple = encode_categorical_variables(y_pred_multiple, exclude_columns=[\"agntnum\"])\n",
    "y_pred_multiple = y_pred_multiple.apply(lambda col: col.astype(int) if col.dtype == 'bool' else col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all columns in y_test_multiple (except last column 'agntnum') is the same as y_pred_multiple.\n",
    "# If it is not the same, it may be due to one hot encoding of less categorical variables than expected due to the prediction model\n",
    "if 'agent_marital_W' not in y_pred_multiple.columns:\n",
    "    y_pred_multiple['agent_marital_W'] = 0\n",
    "    y_pred_multiple = y_pred_multiple[y_test_multiple.columns[:-1]]\n",
    "\n",
    "# This ensures all columns in y_pred_multiple is in the same order as y_test_multiple (except last column 'agntnum') \n",
    "y_pred_multiple = y_pred_multiple[y_test_multiple.columns[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Top 10 Agents\n",
    "Similarity scores are calculated using the cosine similarity score. The top 10 agents are then predicted based on the similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "num_columns = len(y_pred_multiple.columns)  # This number is not equals to labels_to_predict agent_marital has been one hot encoded\n",
    "\n",
    "print(f\"Predicting top {top_k} agents based on {num_columns} columns\")\n",
    "# Calculate Cosine Similarity Matrix with the first \n",
    "similarity_matrix = cosine_similarity(y_pred_multiple.iloc[:, :num_columns], y_multiple.iloc[:, :num_columns]) \n",
    "\n",
    "# Get Top 10 Most Similar Rows for Each Row in y_pred_multiple\n",
    "top_10_matches = [y_multiple.iloc[np.argsort(-row)[:top_k], num_columns].tolist() for row in similarity_matrix]\n",
    "\n",
    "# Add Results to y_pred_multiple as a new column\n",
    "y_pred_multiple[\"top10_agntnum\"] = top_10_matches\n",
    "\n",
    "# Display Output ## Output is removed for data privacy reasons\n",
    "y_pred_multiple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [3375 1660]] \n",
      "\n",
      "Accuracy:\n",
      "0.3297\n"
     ]
    }
   ],
   "source": [
    "y_true = np.ones(len(y_test_multiple[\"agntnum\"]))  # Since we are checking if \"agntnum\" exists, all should be 1\n",
    "y_compared = [1 if agnt in top10 else 0 for agnt, top10 in zip(y_test_multiple[\"agntnum\"], y_pred_multiple[\"top10_agntnum\"])]\n",
    "\n",
    "# Compute Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_compared)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(y_true, y_compared)\n",
    "\n",
    "# 🚀 Print Results\n",
    "print(\"Confusion Matrix:\\n\", cm, \"\\n\")\n",
    "print(f\"Accuracy:\\n{accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Interpretations of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To observe how the model performs on each row:\n",
    "\n",
    "# Assign true false column to prediction df\n",
    "y_pred_multiple['agnt_predicted'] = y_compared\n",
    "\n",
    "# concat true values df (test set) with prediction df\n",
    "y_compare_pred_test = pd.concat([y_test_multiple.reset_index(drop=True),y_pred_multiple.reset_index(drop=True)],axis=1)\n",
    "\n",
    "# look at rows where prediction is wrong ## Output is removed for data privacy reasons\n",
    "y_compare_pred_test[y_compare_pred_test['agnt_predicted']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model for agent_age\n",
      "Saving model for agent_gender_M\n",
      "Saving model for agent_tenure\n",
      "Saving model for agent_marital\n",
      "Saving model for cnt_converted_cat\n",
      "Saving model for annual_premium_cnvrt_cat\n"
     ]
    }
   ],
   "source": [
    "if EXPORT_MODELS == True:\n",
    "    for label_name, model in fitted_models.items():\n",
    "        print(f\"Saving model for {label_name}\")\n",
    "        with open(f\"model/{label_name}_model.pkl\", 'wb') as file:\n",
    "            pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
